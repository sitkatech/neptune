resources:
  repositories:
  - repository: self
    type: git
    ref: develop

    
stages:
- stage: Test
  displayName: Test All
  condition: and(succeeded(), eq(variables['runTests'], 'true'))
  jobs:  
  - job: Tests
    displayName: 'Tests'
    pool:
      vmImage: ubuntu-latest
    steps:
    # - task: DockerCompose@0
    #   displayName: 'Start SQL'
    #   inputs:
    #     containerregistrytype: 'Container Registry'
    #     dockerComposeFile: 'docker-compose/docker-compose-test.yml'
    #     action: 'Run a Docker Compose command'
    #     dockerComposeCommand: 'up -d'

    - task: DotNetCoreCLI@2
      displayName: 'dotnet restore'
      inputs:
        command: restore
        projects: 'Neptune.Tests/Neptune.Tests.csproj'
        
    # - task: replacetokens@3
    #   displayName: 'Create Test environment.json'
    #   inputs:
    #     rootDirectory: 'Neptune.Tests/'
    #     targetFiles: 'environment.json.template => environment.json'
    #     encoding: 'auto'
    #     writeBOM: true
    #     escapeType: 'json'
    #     actionOnMissing: 'fail'
    #     keepToken: false
    #     tokenPrefix: '#{'
    #     tokenSuffix: '}#'

    - task: DotNetCoreCLI@2
      displayName: 'dotnet test'
      inputs:
        command: test
        projects: 'Neptune.Tests/Neptune.Tests.csproj'
        arguments: '--no-restore /p:CollectCoverage=true /p:CoverletOutputFormat=cobertura /p:CoverletOutput=$(Build.SourcesDirectory)/TestResults/Coverage/'
        
    - task: PublishCodeCoverageResults@1
      displayName: 'Publish code coverage report'
      inputs:
        codeCoverageTool: 'Cobertura'
        summaryFileLocation: '$(Build.SourcesDirectory)/**/coverage.cobertura.xml'


- stage: BuildWeb
  displayName: Build API/Web
  dependsOn: Test
  condition: in(dependencies.Test.result, 'Succeeded', 'SucceededWithIssues', 'Skipped')
  jobs:
  - job: BuildAPI
    displayName: Build API
    condition: eq(variables['build'], 'true')
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self
    - task: DockerCompose@0
      displayName: Build API services
      inputs:
        azureSubscriptionEndpoint: '$(azureSubscription)'
        azureContainerRegistry: '$(containerRegistry)'
        dockerComposeFile: docker-compose/docker-compose.yml
        dockerComposeFileArgs: env=$(environment)
        action: Build services
        additionalImageTags: >-
          $(Build.BuildNumber)-$(environment)

          $(environment)
        includeLatestTag: true

    - task: DockerCompose@0
      displayName: Push API Image to Registry  
      condition: eq(variables['pushImages'], 'true')
      inputs:
        azureSubscriptionEndpoint: '$(azureSubscription)'
        azureContainerRegistry: '$(containerRegistry)'
        dockerComposeFile: docker-compose/docker-compose.yml
        dockerComposeFileArgs: env=$(environment)
        action: Push services
        additionalImageTags: >-
          $(Build.BuildNumber)-$(environment)

          $(environment)
        includeLatestTag: true


  - job: BuildWeb
    displayName: Build Web
    condition: eq(variables['build'], 'true')
    pool:
      vmImage: ubuntu-latest
    steps:
    - checkout: self
    - task: DockerCompose@0
      displayName: Build Web services
      inputs:
        azureSubscriptionEndpoint: '$(azureSubscription)'
        azureContainerRegistry: '$(containerRegistry)'
        dockerComposeFile: Neptune.Web/docker-compose/docker-compose.yml
        dockerComposeFileArgs: env=$(environment)
        action: Build services
        additionalImageTags: >-
          $(Build.BuildNumber)-$(environment)

          $(environment)
        includeLatestTag: true


    - task: DockerCompose@0
      displayName: Push Web Image to Registry  
      condition: eq(variables['pushImages'], 'true')
      inputs:
        azureSubscriptionEndpoint: '$(azureSubscription)'
        azureContainerRegistry: '$(containerRegistry)'      
        dockerComposeFile: Neptune.Web/docker-compose/docker-compose.yml
        dockerComposeFileArgs: env=$(environment)
        action: Push services
        additionalImageTags: >-
          $(Build.BuildNumber)-$(environment)

          $(environment)
        includeLatestTag: true
    

- stage: BuildTerraform
  displayName: Terraform Plan
  dependsOn: Test
  condition: in(dependencies.Test.result, 'Succeeded', 'SucceededWithIssues', 'Skipped')  
  jobs:
  - job: Terraform
    displayName: Terraform Plan
    pool:
      vmImage: 'windows-latest'
      demands: msbuild
    steps:
    - task: AzureCLI@1
      displayName: 'Azure CLI'
      inputs:
        azureSubscription: '$(azureSubscription)'
        scriptLocation: inlineScript
        inlineScript: |
          call az storage account create --name $(storageAccountName) --resource-group $(azureApplicationTfStateResourceGroup) --location westus --sku Standard_LRS
          
          call az storage container create --name terraform --account-name $(storageAccountName)
          
    - task: TerraformInstaller@0
      inputs:
        terraformVersion: '0.14.11'

    - task: TerraformCLI@0
      inputs:
        command: 'init'
        backendType: 'azurerm'
        backendServiceArm: '$(azureSubscription)'
        #backendAzureRmSubscriptionId: 'a'
        ensureBackend: true
        backendAzureRmResourceGroupName: '$(azureApplicationTfStateResourceGroup)'
        backendAzureRmResourceGroupLocation: 'WestUS2'
        backendAzureRmStorageAccountName: '$(storageAccountName)'
        backendAzureRmContainerName: 'terraform'
        #backendAzureRmKey: 'd'
        allowTelemetryCollection: true

    # - task: TerraformCLI@0
    #   inputs:
    #     command: 'import'
    #     environmentServiceName: '$(azureSubscription)'
    #     allowTelemetryCollection: true
    #     resourceAddress: 'azurerm_mssql_database.database'
    #     resourceId: '/subscriptions/21fa2974-9388-4e50-a33d-bddc9d3469ca/resourceGroups/aks-spoke-prod/providers/Microsoft.Sql/servers/aks-spoke-prod-sqlserver/databases/NeptuneDB'
    #     commandOptions: '-var "appInsightsName=$(appInsightsName)" -var "keyVaultName=$(keyVaultName)" -var "rabbitMqUser=$(rabbitMqUser)" -var "rabbitMqPass=$(rabbitMqPass)" -var "storageAccountName=$(storageAccountApplicationName)" -var "resourceGroupName=$(resourceGroupName)" -var "dbServerName=$(dbServerName)" -var "aspNetEnvironment=$(aspNetEnvironment)" -var "databaseName=$(databaseName)" -var "databaseEdition=$(databaseEdition)" -var "databaseTier=$(databaseTier)" -var "sqlPassword=$(sqlPassword)" -var "sqlUsername=$(sqlUsername)" -var "azureClusterResourceGroup=$(azureClusterResourceGroup)" -var "sqlApiUsername=$(sqlApiUsername)" -var "sqlGeoserverUsername=$(sqlGeoserverUsername)"'
    #   continueOnError: true #after initial import this should not stop builds until it's removed.

    - task: TerraformCLI@0
      inputs:
        command: 'plan'
        environmentServiceName: '$(azureSubscription)'
        commandOptions: '-var "appInsightsName=$(appInsightsName)" -var "keyVaultName=$(keyVaultName)" -var "rabbitMqUser=$(rabbitMqUser)" -var "rabbitMqPass=$(rabbitMqPass)" -var "storageAccountName=$(storageAccountApplicationName)" -var "resourceGroupName=$(resourceGroupName)" -var "dbServerName=$(dbServerName)" -var "aspNetEnvironment=$(aspNetEnvironment)" -var "databaseName=$(databaseName)" -var "databaseEdition=$(databaseEdition)" -var "databaseTier=$(databaseTier)" -var "sqlPassword=$(sqlPassword)" -var "sqlUsername=$(sqlUsername)" -var "azureClusterResourceGroup=$(azureClusterResourceGroup)" -var "sqlApiUsername=$(sqlApiUsername)" -var "sqlGeoserverUsername=$(sqlGeoserverUsername)" -var "datadogApiKey=$(datadogApiKey)" -var "datadogAppKey=$(datadogAppKey)" -var "domainWeb=$(domainWeb)" -var "domainApi=$(domainApi)" -var "domainGeoserver=$(domainGeoserver)" -var "environment=$(environment)"'
        allowTelemetryCollection: true
        publishPlanResults: 'tfplan'
        

    - publish: 'tfplan'
      artifact: plan
      
    - publish: 'neptune.tf'
      artifact: terraform
    
    - task: CopyFiles@2
      inputs:
        sourceFolder: 'charts/neptune'
        contents: '**'
        targetFolder: $(Build.ArtifactStagingDirectory)/chart
      condition: and(succeeded(), eq(variables['deploy'], 'true'))

    - task: PublishBuildArtifacts@1
      inputs:
        artifactName: ChartArtifacts
        pathtoPublish: $(Build.ArtifactStagingDirectory)
      condition: and(succeeded(), eq(variables['deploy'], 'true'))

    - task: PublishBuildArtifacts@1
      inputs:
        artifactName: GeoServerArtifacts
        pathtoPublish: 'Neptune.GeoServer/data_dir'
      condition: and(succeeded(), eq(variables['deploy'], 'true'))



- stage: BuildDB
  displayName: Build DB
  dependsOn: Test
  condition: in(dependencies.Test.result, 'Succeeded', 'SucceededWithIssues', 'Skipped')
  jobs:
  - template: templates/dacpac-template.yml
    parameters:
      name: 'Database'
      solutionFile: 'Neptune.Database/Neptune.Database.sqlproj'
      additionalArgs: '/p:DSP=Microsoft.Data.Tools.Schema.Sql.SqlAzureV12DatabaseSchemaProvider'
      publishPath: 'Neptune.Database/bin/Debug/Neptune.Database.dacpac'
      artifactName: 'Database'



- stage: DeployTerraform
  displayName: Deploy Terraform (with Approval)
  dependsOn: 
    - BuildWeb
    - BuildDB
    - BuildTerraform
  condition: |
    and
    (
      in(dependencies.BuildWeb.result, 'Succeeded', 'SucceededWithIssues'),
      in(dependencies.BuildDB.result, 'Succeeded', 'SucceededWithIssues'),
      in(dependencies.BuildTerraform.result, 'Succeeded', 'SucceededWithIssues'),
      eq(variables['deploy'], 'true')
    )
  jobs:  
  - deployment: Terraform
    pool:
      vmImage: 'windows-latest'
      demands: msbuild
    # creates an environment if it doesn't exist
    environment: '$(Environment)-Approve' # this Environment has an Approval Gate attached to it in the Azure DevOps UI
    strategy:
      # default deployment strategy, more coming...
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: terraform
                  
          - task: TerraformInstaller@0
            inputs:
              terraformVersion: '0.14.11'

          - task: TerraformCLI@0
            inputs:
              command: 'init'
              workingDirectory: '$(Pipeline.Workspace)/terraform'
              backendType: 'azurerm'
              backendServiceArm: '$(azureSubscription)'
              ensureBackend: true
              backendAzureRmResourceGroupName: '$(azureApplicationTfStateResourceGroup)'
              backendAzureRmResourceGroupLocation: 'WestUS2'
              backendAzureRmStorageAccountName: '$(storageAccountName)'
              backendAzureRmContainerName: 'terraform'
              allowTelemetryCollection: true

          - task: TerraformCLI@0
            inputs:
              command: 'apply'
              workingDirectory: '$(Pipeline.Workspace)/terraform'
              environmentServiceName: '$(azureSubscription)'
              commandOptions: '-var "appInsightsName=$(appInsightsName)" -var "keyVaultName=$(keyVaultName)" -var "rabbitMqUser=$(rabbitMqUser)" -var "rabbitMqPass=$(rabbitMqPass)" -var "storageAccountName=$(storageAccountApplicationName)" -var "resourceGroupName=$(resourceGroupName)" -var "dbServerName=$(dbServerName)" -var "aspNetEnvironment=$(aspNetEnvironment)" -var "databaseName=$(databaseName)" -var "databaseEdition=$(databaseEdition)" -var "databaseTier=$(databaseTier)" -var "sqlPassword=$(sqlPassword)" -var "sqlUsername=$(sqlUsername)" -var "azureClusterResourceGroup=$(azureClusterResourceGroup)"  -var "sqlApiUsername=$(sqlApiUsername)" -var "sqlGeoserverUsername=$(sqlGeoserverUsername)" -var "datadogApiKey=$(datadogApiKey)" -var "datadogAppKey=$(datadogAppKey)" -var "domainWeb=$(domainWeb)" -var "domainApi=$(domainApi)" -var "domainGeoserver=$(domainGeoserver)" -var "environment=$(environment)"'
              allowTelemetryCollection: true

          - task: TerraformCLI@0
            displayName: 'Terraform output'
            inputs:
              command: 'output'
              workingDirectory: '$(Pipeline.Workspace)/terraform'
              
          - bash: |
              echo "##vso[task.setvariable variable=STORAGE_ACCOUNT_SAS_KEY;isOutput=true]$(TF_OUT_STORAGE_ACCOUNT_SAS_KEY)"
              echo "##vso[task.setvariable variable=APPLICATION_STORAGE_ACCOUNT_KEY;isOutput=true]$(TF_OUT_APPLICATION_STORAGE_ACCOUNT_KEY)"
              echo "##vso[task.setvariable variable=INSTRUMENTATION_KEY;isOutput=true]$(TF_OUT_INSTRUMENTATION_KEY)"
              echo "##vso[task.setvariable variable=SQL_API_PASSWORD;isOutput=true;issecret=true]$(TF_OUT_SQL_API_PASSWORD)"
              echo "##vso[task.setvariable variable=SQL_GEOSERVER_PASSWORD;isOutput=true;issecret=true]$(TF_OUT_SQL_GEOSERVER_PASSWORD)"
              echo "##vso[task.setvariable variable=GEOSERVER_ADMIN_PASSWORD;isOutput=true;issecret=true]$(TF_OUT_GEOSERVER_ADMIN_PASSWORD)"
              echo "##vso[task.setvariable variable=HANGFIRE_PASSWORD;isOutput=true;issecret=true]$(TF_OUT_HANGFIRE_PASSWORD)"
          - bash: 'env | sort'

- stage: DeployDB
  displayName: Deploy Database 
  dependsOn: DeployTerraform
  condition: |
    and
    (
      in(dependencies.DeployTerraform.result, 'Succeeded', 'SucceededWithIssues'),
      eq(variables['deploy'], 'true')
    )
  jobs:  
  - deployment: Database
    pool:
      vmImage: 'windows-latest'
      demands: msbuild
    # creates an environment if it doesn't exist
    environment: $(Environment)
    strategy:
      # default deployment strategy, more coming...
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: Database 
          
          - task: DownloadPipelineArtifact@2
            inputs:
              source: 'specific'
              project: 'Neptune'
              pipeline: 'NeptuneDB Backup Job'
              runVersion: 'latest'
              artifact: bacpac  
              path: '$(Pipeline.Workspace)/bacpac'
            condition: and(succeeded(), eq(variables['restoreDatabase'], true))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL InlineSqlTask - Clean Up Old QA DB'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: master
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              deployType: InlineSqlTask
              SqlInline: |
                if exists (select * from sys.databases where name = '$(databaseName)_qa')
                begin
                  drop database [$(databaseName)_qa]
                end  
                if exists (select * from sys.databases where name = '$(databaseName)_prod')
                begin
                  drop database [$(databaseName)_prod]
                end          
                
            condition: and(succeeded(), eq(variables['restoreDatabase'], true))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL InlineSqlTask - Import Prod BacPac'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: '$(databaseName)_prod'
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              DeploymentAction: Import
              BacpacFile: '$(Pipeline.Workspace)/bacpac/$(databaseName).bacpac'
              AdditionalArguments: '/p:DatabaseEdition=$(databaseEdition) /p:DatabaseServiceObjective=$(databaseTier)'
            condition: and(succeeded(), eq(variables['restoreDatabase'], true))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL DacpacTask'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: '$(databaseName)_prod'
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              DacpacFile: '$(Pipeline.Workspace)/Database/Neptune.Database.dacpac'
              AdditionalArguments: '/p:GenerateSmartDefaults=true /p:BlockOnPossibleDataLoss=false /p:DropObjectsNotInSource=true /p:CommandTimeout=600 /TargetTimeout:600 /p:DatabaseEdition=$(databaseEdition) /p:DatabaseServiceObjective=$(databaseTier)'
            condition: and(succeeded(), eq(variables['restoreDatabase'], true))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL DacpacTask NoRestore'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: '$(databaseName)'
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              DacpacFile: '$(Pipeline.Workspace)/Database/Neptune.Database.dacpac'
              AdditionalArguments: '/p:GenerateSmartDefaults=true /p:BlockOnPossibleDataLoss=false /p:DropObjectsNotInSource=true /p:CommandTimeout=600 /TargetTimeout:600 /p:DatabaseEdition=$(databaseEdition) /p:DatabaseServiceObjective=$(databaseTier)'
            condition: and(succeeded(), eq(variables['restoreDatabase'], false))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL InlineSqlTask - Swap DBs'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: master
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              deployType: InlineSqlTask
              SqlInline: |
                ALTER DATABASE [$(databaseName)] MODIFY NAME = [$(databaseName)_qa]
                GO                
                ALTER DATABASE [$(databaseName)_prod] MODIFY NAME = [$(databaseName)]
                GO
                drop database [$(databaseName)_qa]
              
            condition: and(succeeded(), eq(variables['restoreDatabase'], true))

          - task: SqlAzureDacpacDeployment@1
            displayName: 'Azure SQL InlineSqlTask - Rename Users'
            inputs:
              azureSubscription: '$(azureSubscription)'
              ServerName: '$(dbServer)' 
              DatabaseName: $(databaseName)
              SqlUsername: '$(sqlUsername)'
              SqlPassword: '$(sqlPassword)'
              deployType: InlineSqlTask
              SqlInline: |
                if not exists (select * from sys.database_principals where name = N'$(sqlApiUsername)')
                  BEGIN
                    CREATE USER [$(sqlApiUsername)] FOR LOGIN [$(sqlApiUsername)] WITH DEFAULT_SCHEMA=[dbo]
                    EXEC sp_addrolemember 'db_datawriter', '$(sqlApiUsername)'
                    EXEC sp_addrolemember 'db_datareader', '$(sqlApiUsername)'
                    GRANT EXECUTE ON SCHEMA::dbo TO $(sqlApiUsername)
                  END
                                
                if not exists (select * from sys.database_principals where name = N'$(sqlGeoserverUsername)')
                  BEGIN
                    CREATE USER [$(sqlGeoserverUsername)] FOR LOGIN [$(sqlGeoserverUsername)] WITH DEFAULT_SCHEMA=[dbo]
                    EXEC sp_addrolemember 'db_datareader', '$(sqlGeoserverUsername)'              
                  END
            condition: succeeded()


- stage: DeployGeoServer
  displayName: Deploy GeoServer
  dependsOn: DeployTerraform
  condition: |
    and
    (
      in(dependencies.DeployTerraform.result, 'Succeeded', 'SucceededWithIssues'),
      eq(variables['deploy'], 'true')
    )
  jobs:  
  - deployment: GeoServer
    pool:
      vmImage: 'windows-latest'
    variables: 
      STORAGE_ACCOUNT_SAS_KEY: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.STORAGE_ACCOUNT_SAS_KEY'] ]
    # creates an environment if it doesn't exist
    environment: $(Environment)
    strategy:
      # default deployment strategy, more coming...
      runOnce:
        deploy:
          steps:        
          - download: current
            artifact: GeoServerArtifacts
          - bash: |
              echo "variable value is $(STORAGE_ACCOUNT_SAS_KEY)"
             
          - task: AzureCLI@2
            inputs:
              azureSubscription: '$(azureSubscription)'
              scriptType: 'ps'
              scriptLocation: 'inlineScript'
              inlineScript: |
                azcopy copy "$(Pipeline.Workspace)\GeoServerArtifacts\*" "https://$(storageAccountApplicationName).file.core.windows.net/geoserver/data_dir/$(STORAGE_ACCOUNT_SAS_KEY)" --from-to=LocalFile --recursive


- stage: DeployHelm
  displayName: Deploy Helm
  dependsOn: 
  - DeployGeoServer
  - DeployDB
  - DeployTerraform
  condition: |
    and
    (
      in(dependencies.DeployGeoServer.result, 'Succeeded', 'SucceededWithIssues'),
      in(dependencies.DeployDB.result, 'Succeeded', 'SucceededWithIssues'),
      in(dependencies.DeployTerraform.result, 'Succeeded', 'SucceededWithIssues'),
      eq(variables['deploy'], 'true')
    )
  jobs:  
  - deployment: Helm
    pool:
      vmImage: 'ubuntu-latest'
    variables: 
      APPLICATION_STORAGE_ACCOUNT_KEY: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.APPLICATION_STORAGE_ACCOUNT_KEY'] ]
      INSTRUMENTATION_KEY: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.INSTRUMENTATION_KEY'] ]
      SQL_API_PASSWORD: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.SQL_API_PASSWORD'] ]
      SQL_GEOSERVER_PASSWORD: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.SQL_GEOSERVER_PASSWORD'] ]
      GEOSERVER_ADMIN_PASSWORD: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.GEOSERVER_ADMIN_PASSWORD'] ]
      HANGFIRE_PASSWORD: $[ stageDependencies.DeployTerraform.Terraform.outputs['Terraform.Bash.HANGFIRE_PASSWORD'] ]
    # creates an environment if it doesn't exist
    environment: $(Environment)
    strategy:
      # default deployment strategy, more coming...
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: ChartArtifacts
                        
          - task: HelmInstaller@0
            displayName: 'Install Helm 3.8.0'
            inputs:
              helmVersion: 3.8.0
              installKubectl: true

          - task: Kubernetes@1
            displayName: 'kubectl login'
            inputs:
              connectionType: Azure Resource Manager
              azureSubscriptionEndpoint: '$(azureSubscription)'
              azureResourceGroup: '$(azureClusterResourceGroup)'
              kubernetesCluster: '$(kubernetesCluster)'
              command: login

          - task: HelmDeploy@0
            displayName: 'helm repo add rabbitmq'
            inputs:
              connectionType: Azure Resource Manager
              azureSubscription: '$(azureSubscription)'
              azureResourceGroup: '$(azureClusterResourceGroup)'
              kubernetesCluster: '$(kubernetesCluster)'
              command: 'repo'
              arguments: 'azure-marketplace https://marketplace.azurecr.io/helm/v1/repo'

          - task: HelmDeploy@0
            displayName: 'helm dependency update'
            inputs:
              connectionType: Azure Resource Manager
              azureSubscription: '$(azureSubscription)'
              azureResourceGroup: '$(azureClusterResourceGroup)'
              kubernetesCluster: '$(kubernetesCluster)'
              command: 'dependency'
              arguments: 'update $(Pipeline.Workspace)/ChartArtifacts/chart'

          - task: HelmDeploy@0
            displayName: 'helm upgrade neptune'
            inputs:
              connectionType: Azure Resource Manager
              azureSubscription: '$(azureSubscription)'
              azureResourceGroup: '$(azureClusterResourceGroup)'
              kubernetesCluster: '$(kubernetesCluster)'
              namespace: 'h2o'
              arguments: '--create-namespace'
              command: upgrade
              chartType: FilePath
              chartPath: '$(Pipeline.Workspace)/ChartArtifacts/chart'
              releaseName: 'neptune'
              overrideValues: |
                global.env.appInsightsInstrumentationKey="$(INSTRUMENTATION_KEY)"
                global.domains.api="$(domainApi)"
                global.domains.web="$(domainWeb)"
                global.domains.geoserver="$(domainGeoserver)"
                global.domains.swaggerApi="$(domainSwaggerApi)"
                global.env.name="$(Environment)"
                global.secrets.geoserverSqlServerPassword="$(SQL_GEOSERVER_PASSWORD)"
                global.secrets.geoserverAdminPassword="$(GEOSERVER_ADMIN_PASSWORD)"
                global.secrets.applicationStorageAccountName="$(storageAccountApplicationName)"
                global.secrets.applicationStorageAccountKey="$(APPLICATION_STORAGE_ACCOUNT_KEY)"
                global.env.dbServer=$(dbServer)
                global.env.databaseName=$(databaseName)
                global.env.sqlUsername=$(sqlApiUsername)
                global.env.sqlGeoserverUsername=$(sqlGeoserverUsername)
                global.secrets.apiSqlPassword=$(SQL_API_PASSWORD)
                global.secrets.sendGridApiKey="$(SendGridApiKey)"
                global.env.rabbitMqUser=$(rabbitMqUser)
                global.secrets.rabbitMqPass="$(rabbitMqPass)"
                global.env.getApiSubscriptionKey=$(getApiSubscriptionKey)
                rabbitmq.auth.username="$(rabbitMqUser)"
                rabbitmq.auth.password="$(rabbitMqPass)"
                api.image.tag="$(Build.BuildNumber)-$(environment)"
                web.image.tag="$(Build.BuildNumber)-$(environment)"
                api.image.repository="$(containerRegistry)/neptune/api"
                web.image.repository="$(containerRegistry)/neptune/web"
                global.secrets.hangfirePassword="$(HANGFIRE_PASSWORD)"
                global.secrets.openETApiKey="$(openETApiKey)"
                global.secrets.neptuneApiKey="$(neptuneApiKey)"
              force: false
